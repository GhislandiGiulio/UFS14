{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b1bfd0",
   "metadata": {},
   "source": [
    "# Inferenza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6416c",
   "metadata": {},
   "source": [
    "### In Locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2202f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bb9d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 13:30:00.066290: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"abalone_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6617fe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"predict_result\": [[0.0]]}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_input = np.array([[0.475,0.37,0.125,0.5095,0.2165,0.1125,0.165,9]])\n",
    "predict_result = model.predict(predict_input)\n",
    "\n",
    "json.dumps({\"predict_result\": predict_result.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12da3a",
   "metadata": {},
   "source": [
    "### In Remoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691c47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from sagemaker import image_uris\n",
    "image_uris.retrieve(framework='tensorflow',region='us-east-1',version='2.12.1',image_scope='inference',instance_type='ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bd1c6",
   "metadata": {},
   "source": [
    "Quella prodotta dalla cella sopra sarà la URL dell'immagine da usare all'intero del Dockerfile.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d5be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ed058d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/3)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.inference             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 456B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws  0.1s\n",
      "\u001b[0m\u001b[34m => [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazona  0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (9/11)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.inference             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 456B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws  0.1s\n",
      "\u001b[0m\u001b[34m => [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazona  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-in  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.21kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] ADD requirements-inference.txt /opt/requirements.txt      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] RUN pip3 install -r /opt/requirements.txt                 0.0s\n",
      "\u001b[0m\u001b[34m => [4/6] ADD ./inference.py /opt/inference.py                             0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (11/11)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.inference             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 456B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws  0.1s\n",
      "\u001b[0m\u001b[34m => [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazona  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-in  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.21kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] ADD requirements-inference.txt /opt/requirements.txt      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] RUN pip3 install -r /opt/requirements.txt                 0.0s\n",
      "\u001b[0m\u001b[34m => [4/6] ADD ./inference.py /opt/inference.py                             0.1s\n",
      "\u001b[0m\u001b[34m => [5/6] ADD ./abalone_model.keras /model/abalone_model.keras             0.1s\n",
      "\u001b[0m\u001b[34m => [6/6] ADD ./test.sh /opt/test.sh                                       0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (11/12)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.inference             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 456B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws  0.1s\n",
      "\u001b[0m\u001b[34m => [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazona  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-in  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.21kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] ADD requirements-inference.txt /opt/requirements.txt      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] RUN pip3 install -r /opt/requirements.txt                 0.0s\n",
      "\u001b[0m\u001b[34m => [4/6] ADD ./inference.py /opt/inference.py                             0.1s\n",
      "\u001b[0m\u001b[34m => [5/6] ADD ./abalone_model.keras /model/abalone_model.keras             0.1s\n",
      "\u001b[0m\u001b[34m => [6/6] ADD ./test.sh /opt/test.sh                                       0.1s\n",
      "\u001b[0m => exporting to image                                                     0.1s\n",
      "\u001b[34m => => exporting layers                                                    0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (12/12) FINISHED                               docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.inference             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 456B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws  0.1s\n",
      "\u001b[0m\u001b[34m => [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazona  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-in  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.21kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] ADD requirements-inference.txt /opt/requirements.txt      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] RUN pip3 install -r /opt/requirements.txt                 0.0s\n",
      "\u001b[0m\u001b[34m => [4/6] ADD ./inference.py /opt/inference.py                             0.1s\n",
      "\u001b[0m\u001b[34m => [5/6] ADD ./abalone_model.keras /model/abalone_model.keras             0.1s\n",
      "\u001b[0m\u001b[34m => [6/6] ADD ./test.sh /opt/test.sh                                       0.1s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.2s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.1s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:fd85832eb662572d19eb7ebc0cb9f3a79cbb28b03c274  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/inference-housing-container             0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build -t inference-housing-container -f Dockerfile.inference ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "757d5c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                          TAG                        IMAGE ID       CREATED             SIZE\n",
      "inference-housing-container                                         latest                     c4cf3825c044   3 seconds ago       4.53GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference   2.12.1-cpu                 5d3d4cdcecea   About an hour ago   4.53GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference   2.12.1-cpu-2               5d3d4cdcecea   About an hour ago   4.53GB\n",
      "<none>                                                              <none>                     47af834b9884   About an hour ago   4.53GB\n",
      "<none>                                                              <none>                     d5fd7fcca2db   About an hour ago   4.53GB\n",
      "<none>                                                              <none>                     bac0b3a3cbe0   About an hour ago   4.53GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference   <none>                     60f5d0d6063e   2 hours ago         4.53GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference   <none>                     3cfaa5c3cfe7   2 hours ago         4.53GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference   <none>                     e8b83e27552d   2 hours ago         4.53GB\n",
      "training-housing-container                                          latest                     224490f9763c   2 hours ago         14.3GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training    2.12.0-cpu-py310-housing   224490f9763c   2 hours ago         14.3GB\n",
      "<none>                                                              <none>                     b65c04ae7e13   3 hours ago         14.3GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce3d024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name: tensorflow-inference ######################\n",
      "account: 891377019371 ######################\n",
      "region: us-east-1 ######################\n",
      "fullname: 891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (RepositoryNotFoundException) when calling the DescribeRepositories operation: The repository with name 'tensorflow-inference' does not exist in the registry with id '891377019371'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:us-east-1:891377019371:repository/tensorflow-inference\",\n",
      "        \"registryId\": \"891377019371\",\n",
      "        \"repositoryName\": \"tensorflow-inference\",\n",
      "        \"repositoryUri\": \"891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference\",\n",
      "        \"createdAt\": 1732282624.629,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": false\n",
      "        },\n",
      "        \"encryptionConfiguration\": {\n",
      "            \"encryptionType\": \"AES256\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# Specify an image name\n",
    "image_name=tensorflow-inference\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:2.12.1-cpu\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\"\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0da8b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 891377019371.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7112c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag inference-housing-container 891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c140787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference]\n",
      "\n",
      "\u001b[1B03ce7bad: Preparing \n",
      "\u001b[1Bead4aac3: Preparing \n",
      "\u001b[1B474f827d: Preparing \n",
      "\u001b[1B12a822d4: Preparing \n",
      "\u001b[1B40c2c70a: Preparing \n",
      "\u001b[1B37bf1d61: Preparing \n",
      "\u001b[1B8df97c44: Preparing \n",
      "\u001b[1B764747b4: Preparing \n",
      "\u001b[1B1a68f579: Preparing \n",
      "\u001b[1B2eef5eea: Preparing \n",
      "\u001b[1Bb5bcc575: Preparing \n",
      "\u001b[1B5e5ce62f: Preparing \n",
      "\u001b[1B757a305d: Preparing \n",
      "\u001b[1Bc7cf6f28: Preparing \n",
      "\u001b[1B30092134: Preparing \n",
      "\u001b[1Bfb153852: Preparing \n",
      "\u001b[1B0903db8c: Preparing \n",
      "\u001b[1B19dec72a: Preparing \n",
      "\u001b[1Bdf04f233: Preparing \n",
      "\u001b[1Bf2dbc490: Preparing \n",
      "\u001b[1Bba0431f9: Preparing \n",
      "\u001b[1B71536788: Preparing \n",
      "\u001b[1B994107ae: Preparing \n",
      "\u001b[1B3a4f83e7: Preparing \n",
      "\u001b[1Bd6748243: Preparing \n",
      "\u001b[1Bf2c1e372: Preparing \n",
      "\u001b[1Bcd2b5d6d: Preparing \n",
      "\u001b[1Bca73c74f: Layer already exists 7kB6A\u001b[2K\u001b[27A\u001b[2K\u001b[19A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[13A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K2.12.1-cpu-8: digest: sha256:9e29e5dd7576fa830381998c10a6f87cbd2f98c9695aced359041a102b2cb7d6 size: 6180\n"
     ]
    }
   ],
   "source": [
    "!docker push 891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5398834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "aws_region = my_session.region_name\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "model_name = 'housing-price-prediction-8'\n",
    "\n",
    "# Create model\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': '891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu-8',\n",
    "        'ModelDataUrl': 's3://itsarghisdata/data/output/tensorflow-training-2024-11-22-13-42-34-960/output/model.tar.gz',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bf75349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:891377019371:endpoint-config/housing-inf-8\n"
     ]
    }
   ],
   "source": [
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = 'housing-inf-8'\n",
    "\n",
    "instance_type = 'ml.m5.large'\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = 'housing-inference-endpoint-8'\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a84b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
