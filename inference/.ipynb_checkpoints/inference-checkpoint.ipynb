{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711759b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 19:43:12.592031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-21 19:43:12.621388: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-21 19:43:12.621419: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 19:43:12.640353: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-21 19:43:20.258771: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dfa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"abalone_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input = np.array([[0.475,0.37,0.125,0.5095,0.2165,0.1125,0.165,9]])\n",
    "predict_result = model.predict(predict_input)\n",
    "\n",
    "json.dumps({\"predict_result\": predict_result.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1255380",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf228dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from sagemaker import image_uris\n",
    "image_uris.retrieve(framework='tensorflow',region='us-east-1',version='2.12.1',image_scope='inference',instance_type='ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d661f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4156a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name: tensorflow-inference ######################\n",
      "account: 891377019371 ######################\n",
      "region: us-east-1 ######################\n",
      "fullname: 891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu-pluto ######################\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-east-1:891377019371:repository/tensorflow-inference\",\n",
      "            \"registryId\": \"891377019371\",\n",
      "            \"repositoryName\": \"tensorflow-inference\",\n",
      "            \"repositoryUri\": \"891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference\",\n",
      "            \"createdAt\": 1730815819.268,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# Specify an image name\n",
    "image_name=tensorflow-inference\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:2.12.1-cpu-pluto\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\"\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "033d0c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/3)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.inference             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws  0.1s\n",
      "\u001b[0m\u001b[34m => [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazona  0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (10/10) FINISHED                               docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.inference             0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 357B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws  0.1s\n",
      "\u001b[0m\u001b[34m => [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazona  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-in  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 79B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] ADD requirements-inference.txt /opt/requirements.txt      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/4] RUN pip3 install -r /opt/requirements.txt                 0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/4] ADD ./inference.py /opt/inference.py                      0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:caf86922fa39b7c822905cc5af48acdcb9f06459ec13a  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to 891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-  0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build -t 891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu-pluto-2 -f Dockerfile.inference ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e62fc579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                  TAG                        IMAGE ID       CREATED          SIZE\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference           2.12.1-cpu-pluto           caf86922fa39   23 minutes ago   4.53GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference           2.12.1-cpu-pluto-2         caf86922fa39   23 minutes ago   4.53GB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference           2.12.0-cpu-py310-pluto-2   bb569760a7b4   23 minutes ago   4.53GB\n",
      "520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving   1.12.0-cpu                 27aee10a9f6a   5 years ago      377MB\n",
      "891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference           <none>                     6c4e927c7041   5 years ago      377MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eaaef6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 891377019371.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53f4749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference]\n",
      "\n",
      "\u001b[1Bca06d39a: Preparing \n",
      "\u001b[1Bce09b50a: Preparing \n",
      "\u001b[1Bc410fb44: Preparing \n",
      "\u001b[1B37bf1d61: Preparing \n",
      "\u001b[1B8df97c44: Preparing \n",
      "\u001b[1B764747b4: Preparing \n",
      "\u001b[1B1a68f579: Preparing \n",
      "\u001b[1B2eef5eea: Preparing \n",
      "\u001b[1Bb5bcc575: Preparing \n",
      "\u001b[1B5e5ce62f: Preparing \n",
      "\u001b[1B757a305d: Preparing \n",
      "\u001b[1Bc7cf6f28: Preparing \n",
      "\u001b[1B30092134: Preparing \n",
      "\u001b[1Bfb153852: Preparing \n",
      "\u001b[1B0903db8c: Preparing \n",
      "\u001b[1B19dec72a: Preparing \n",
      "\u001b[1Bdf04f233: Preparing \n",
      "\u001b[1Bf2dbc490: Preparing \n",
      "\u001b[1Bba0431f9: Preparing \n",
      "\u001b[1B71536788: Preparing \n",
      "\u001b[1B994107ae: Preparing \n",
      "\u001b[1B3a4f83e7: Preparing \n",
      "\u001b[1Bd6748243: Preparing \n",
      "\u001b[1Bf2c1e372: Preparing \n",
      "\u001b[1Bcd2b5d6d: Preparing \n",
      "\u001b[1Bca73c74f: Layer already exists \u001b[21A\u001b[2K\u001b[16A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K2.12.1-cpu-pluto-2: digest: sha256:2e99d61437ad796dadfd95fe2ddc7c7b23a0acfdcad64eef94731e261210b7f4 size: 5765\n"
     ]
    }
   ],
   "source": [
    "!docker push 891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu-pluto-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8561382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "aws_region = my_session.region_name\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "model_name = 'training-2023-11-23-18-45-31-074'\n",
    "\n",
    "# Create model\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': '891377019371.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu-pluto-2',\n",
    "        'ModelDataUrl': 's3://asdnajsndalkas/data/output/training_job-2024-11-05-14-05-20/output/model.tar.gz',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f628e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:891377019371:endpoint-config/test-api-inference\n"
     ]
    }
   ],
   "source": [
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = 'test-api-inference'\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = 'test-endpoint-inference'\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d04b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
